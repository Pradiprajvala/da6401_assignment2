{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11445564,"sourceType":"datasetVersion","datasetId":7170423}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nos.environ[\"WANDB_API_KEY\"] = \"47aa32aca06bea662b4b8c2246cefcb55bd15dab\"\n!wandb login","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:36:06.420751Z","iopub.execute_input":"2025-04-19T06:36:06.420975Z","iopub.status.idle":"2025-04-19T06:36:07.931948Z","shell.execute_reply.started":"2025-04-19T06:36:06.420955Z","shell.execute_reply":"2025-04-19T06:36:07.931052Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m012\u001b[0m (\u001b[33mda24m012-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport time\nimport os\nimport wandb\nimport datetime\nimport socket\nimport platform\nimport random\nimport string\n\n# This function crafts a unique and descriptive name for each WandB run\ndef generate_run_name(model_name, batch_size, lr, num_classes):\n    date_str = datetime.datetime.now().strftime(\"%m%d\")\n    rand_suffix = ''.join(random.choices(string.ascii_lowercase, k=3))\n    run_name = f\"{model_name}-c{num_classes}-b{batch_size}-lr{lr:.1e}-{date_str}-{rand_suffix}\"\n    return run_name\n\n# Handles one full training pass through the data\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    \n    for inputs, labels in dataloader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += inputs.size(0)\n    \n    epoch_loss = running_loss / total_samples\n    epoch_acc = running_corrects.double() / total_samples\n    \n    return epoch_loss, epoch_acc.item()\n\n# Runs evaluation for one epoch, without updating model weights\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    total_samples = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n            total_samples += inputs.size(0)\n    \n    epoch_loss = running_loss / total_samples\n    epoch_acc = running_corrects.double() / total_samples\n    \n    return epoch_loss, epoch_acc.item()\n\n# Full training loop across multiple epochs with logging, saving, and tracking\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, model_name, num_epochs=15):\n    start_time = time.time()\n    best_acc = 0.0\n    \n    train_losses = []\n    val_losses = []\n    train_accs = []\n    val_accs = []\n    \n    os.makedirs('models', exist_ok=True)\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        \n        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n        \n        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        \n        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n        \n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_accuracy\": val_acc,\n            \"learning_rate\": optimizer.param_groups[0]['lr']\n        })\n        \n        scheduler.step()\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            model_path = os.path.join('models', f'best_model_{wandb.run.name}.pth')\n            torch.save(model.state_dict(), model_path)\n            wandb.save(model_path)\n            print(f'New best model saved with accuracy: {best_acc:.4f}')\n            \n            artifact = wandb.Artifact(f\"model-{wandb.run.id}\", type=\"model\")\n            artifact.add_file(model_path)\n            wandb.log_artifact(artifact)\n    \n    time_elapsed = time.time() - start_time\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    wandb.run.summary[\"best_val_accuracy\"] = best_acc\n    wandb.run.summary[\"training_time\"] = time_elapsed\n    \n    model.load_state_dict(torch.load(os.path.join('models', f'best_model_{wandb.run.name}.pth')))\n    \n    return model, train_losses, val_losses, train_accs, val_accs\n\n# Evaluates trained model on a test set and logs useful stats\ndef evaluate_model(model, dataloader, device, class_names):\n    model.eval()\n    corrects = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n    class_correct = list(0. for i in range(len(class_names)))\n    class_total = list(0. for i in range(len(class_names)))\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            corrects += torch.sum(preds == labels.data)\n            total += labels.size(0)\n            \n            c = (preds == labels).squeeze()\n            for i in range(labels.size(0)):\n                label = labels[i]\n                class_correct[label] += c[i].item()\n                class_total[label] += 1\n                \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    test_acc = corrects.double() / total\n    print(f'Test Accuracy: {test_acc:.4f}')\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    \n    class_accuracy = {}\n    for i in range(len(class_names)):\n        if class_total[i] > 0:\n            acc = class_correct[i] / class_total[i]\n            print(f'Accuracy of {class_names[i]}: {100 * acc:.2f}%')\n            class_accuracy[f\"class_acc_{class_names[i]}\"] = acc\n    \n    wandb.run.summary[\"test_accuracy\"] = test_acc.item()\n    wandb.run.summary.update(class_accuracy)\n    \n    wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n        probs=None,\n        y_true=all_labels,\n        preds=all_preds,\n        class_names=class_names)\n    })\n    \n    return test_acc.item(), cm\n\n# Saves and logs plots for loss/accuracy and confusion matrix\ndef plot_results(train_losses, val_losses, train_accs, val_accs, cm, class_names):\n    os.makedirs('plots', exist_ok=True)\n    \n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, len(train_accs) + 1), train_accs, label='Train Accuracy')\n    plt.plot(range(1, len(val_accs) + 1), val_accs, label='Val Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt_path = os.path.join('plots', f'training_curves_{wandb.run.name}.png')\n    plt.savefig(plt_path)\n    wandb.log({\"training_curves\": wandb.Image(plt_path)})\n    plt.close()\n    \n    plt.figure(figsize=(10, 8))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n    plt.yticks(tick_marks, class_names)\n    \n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, format(cm[i, j], 'd'),\n                     ha=\"center\", va=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.tight_layout()\n    cm_path = os.path.join('plots', f'confusion_matrix_{wandb.run.name}.png')\n    plt.savefig(cm_path)\n    wandb.log({\"confusion_matrix_plot\": wandb.Image(cm_path)})\n    plt.close()\n\n# Prints out which model layers will be trained\ndef print_params_to_train(model):\n    print(\"Layers being trained:\")\n    params_to_train = []\n    for name, param in model.named_parameters():\n        if param.requires_grad:\n            params_to_train.append(name)\n    print(f\"Parameters to train: {params_to_train}\")\n\n# Main script to set everything up and kick off training\ndef main():\n    torch.manual_seed(42)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(42)\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using {device} device\")\n\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    data_dir = \"/kaggle/input/nature-12k/inaturalist_12K\"\n    train_dir = os.path.join(data_dir, \"train\")\n    val_dir = os.path.join(data_dir, \"val\")\n\n    full_train_dataset = ImageFolder(train_dir, transform=transform)\n    test_dataset = ImageFolder(val_dir, transform=transform)\n\n    train_size = int(0.8 * len(full_train_dataset))\n    val_size = len(full_train_dataset) - train_size\n\n    train_dataset, val_dataset = random_split(\n        full_train_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n\n    batch_size = 32\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    class_names = full_train_dataset.classes\n    num_classes = len(class_names)\n    print(f\"Number of classes: {num_classes}\")\n    print(f\"Class names: {class_names}\")\n    print(f\"Train dataset size: {len(train_dataset)}\")\n    print(f\"Validation dataset size: {len(val_dataset)}\")\n    print(f\"Test dataset size: {len(test_dataset)}\")\n\n    model_name = \"resnet50\"\n    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, num_classes)\n\n    for param in model.fc.parameters():\n        param.requires_grad = True\n\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    learning_rate = 0.001\n    optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n    print_params_to_train(model)\n    num_epochs = 15\n    run_name = generate_run_name(model_name, batch_size, learning_rate, num_classes)\n\n    wandb.init(\n        project=\"A2\",\n        name=run_name,\n        config={\n            \"architecture\": model_name,\n            \"dataset\": data_dir,\n            \"epochs\": num_epochs,\n            \"batch_size\": batch_size,\n            \"learning_rate\": learning_rate,\n            \"optimizer\": optimizer.__class__.__name__,\n            \"scheduler\": scheduler.__class__.__name__,\n            \"scheduler_step_size\": scheduler.step_size,\n            \"scheduler_gamma\": scheduler.gamma,\n            \"num_classes\": num_classes,\n            \"class_names\": class_names,\n            \"device\": device.type,\n            \"frozen_backbone\": True,\n            \"system_info\": f\"{platform.system()} {platform.release()} - {socket.gethostname()}\",\n            \"train_size\": len(train_dataset),\n            \"val_size\": len(val_dataset),\n            \"test_size\": len(test_dataset)\n        }\n    )\n    \n    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n    \n    print(\"Starting model training...\")\n    model, train_losses, val_losses, train_accs, val_accs = train_model(\n        model, train_loader, val_loader, criterion, optimizer, scheduler, device, model_name, num_epochs\n    )\n    \n    print(\"Evaluating model on test set...\")\n    test_acc, cm = evaluate_model(model, test_loader, device, class_names)\n    \n    plot_results(train_losses, val_losses, train_accs, val_accs, cm, class_names)\n    \n    print(f\"Final test accuracy: {test_acc:.4f}\")\n    print(f\"WandB run: {wandb.run.name}\")\n    \n    model_artifact = wandb.Artifact(\n        f\"trained-model-{wandb.run.id}\", \n        type=\"model\",\n        description=f\"Final trained {model_name} model on naturalist dataset\"\n    )\n    model_path = os.path.join(\"models\", f\"final_model_{wandb.run.name}.pth\")\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'epoch': num_epochs,\n        'test_accuracy': test_acc,\n        'class_names': class_names\n    }, model_path)\n    model_artifact.add_file(model_path)\n    wandb.log_artifact(model_artifact)\n    \n    wandb.finish()\n    print(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:37:00.152186Z","iopub.execute_input":"2025-04-19T06:37:00.152505Z","iopub.status.idle":"2025-04-19T06:37:00.190112Z","shell.execute_reply.started":"2025-04-19T06:37:00.152483Z","shell.execute_reply":"2025-04-19T06:37:00.189303Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:37:01.717477Z","iopub.execute_input":"2025-04-19T06:37:01.717782Z","iopub.status.idle":"2025-04-19T06:58:02.164585Z","shell.execute_reply.started":"2025-04-19T06:37:01.717744Z","shell.execute_reply":"2025-04-19T06:58:02.163817Z"}},"outputs":[{"name":"stdout","text":"Using cuda:0 device\nNumber of classes: 10\nClass names: ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\nTrain dataset size: 7999\nValidation dataset size: 2000\nTest dataset size: 2000\nLayers being trained:\nParameters to train: ['fc.weight', 'fc.bias']\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m012\u001b[0m (\u001b[33mda24m012-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_063712-tkutrcpc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m012-iit-madras/A2/runs/tkutrcpc' target=\"_blank\">resnet50-c10-b32-lr1.0e-03-0419-ugx</a></strong> to <a href='https://wandb.ai/da24m012-iit-madras/A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m012-iit-madras/A2' target=\"_blank\">https://wandb.ai/da24m012-iit-madras/A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m012-iit-madras/A2/runs/tkutrcpc' target=\"_blank\">https://wandb.ai/da24m012-iit-madras/A2/runs/tkutrcpc</a>"},"metadata":{}},{"name":"stdout","text":"Starting model training...\nEpoch 1/15\n----------\nTrain Loss: 1.1446 Acc: 0.6973\nVal Loss: 0.7688 Acc: 0.7965\nNew best model saved with accuracy: 0.7965\nEpoch 2/15\n----------\nTrain Loss: 0.6686 Acc: 0.8131\nVal Loss: 0.6179 Acc: 0.8310\nNew best model saved with accuracy: 0.8310\nEpoch 3/15\n----------\nTrain Loss: 0.5562 Acc: 0.8369\nVal Loss: 0.5805 Acc: 0.8320\nNew best model saved with accuracy: 0.8320\nEpoch 4/15\n----------\nTrain Loss: 0.4934 Acc: 0.8542\nVal Loss: 0.5589 Acc: 0.8330\nNew best model saved with accuracy: 0.8330\nEpoch 5/15\n----------\nTrain Loss: 0.4472 Acc: 0.8654\nVal Loss: 0.5449 Acc: 0.8300\nEpoch 6/15\n----------\nTrain Loss: 0.4224 Acc: 0.8715\nVal Loss: 0.5307 Acc: 0.8400\nNew best model saved with accuracy: 0.8400\nEpoch 7/15\n----------\nTrain Loss: 0.3827 Acc: 0.8822\nVal Loss: 0.5422 Acc: 0.8355\nEpoch 8/15\n----------\nTrain Loss: 0.3457 Acc: 0.8997\nVal Loss: 0.5337 Acc: 0.8380\nEpoch 9/15\n----------\nTrain Loss: 0.3437 Acc: 0.9002\nVal Loss: 0.5319 Acc: 0.8320\nEpoch 10/15\n----------\nTrain Loss: 0.3427 Acc: 0.9002\nVal Loss: 0.5329 Acc: 0.8385\nEpoch 11/15\n----------\nTrain Loss: 0.3402 Acc: 0.8991\nVal Loss: 0.5280 Acc: 0.8365\nEpoch 12/15\n----------\nTrain Loss: 0.3424 Acc: 0.8992\nVal Loss: 0.5218 Acc: 0.8415\nNew best model saved with accuracy: 0.8415\nEpoch 13/15\n----------\nTrain Loss: 0.3327 Acc: 0.9009\nVal Loss: 0.5243 Acc: 0.8455\nNew best model saved with accuracy: 0.8455\nEpoch 14/15\n----------\nTrain Loss: 0.3329 Acc: 0.9040\nVal Loss: 0.5329 Acc: 0.8350\nEpoch 15/15\n----------\nTrain Loss: 0.3291 Acc: 0.9024\nVal Loss: 0.5244 Acc: 0.8395\nTraining complete in 20m 20s\nBest val Acc: 0.8455\nEvaluating model on test set...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_552/110366834.py:154: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(os.path.join('models', f'best_model_{wandb.run.name}.pth')))\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.8440\nAccuracy of Amphibia: 85.00%\nAccuracy of Animalia: 80.00%\nAccuracy of Arachnida: 82.50%\nAccuracy of Aves: 93.00%\nAccuracy of Fungi: 87.00%\nAccuracy of Insecta: 82.00%\nAccuracy of Mammalia: 90.00%\nAccuracy of Mollusca: 81.00%\nAccuracy of Plantae: 79.00%\nAccuracy of Reptilia: 84.50%\nFinal test accuracy: 0.8440\nWandB run: resnet50-c10-b32-lr1.0e-03-0419-ugx\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>learning_rate</td><td>███████▂▂▂▂▂▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▆▆▆▇▇▇▆▇▇▇█▆▇</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.8455</td></tr><tr><td>class_acc_Amphibia</td><td>0.85</td></tr><tr><td>class_acc_Animalia</td><td>0.8</td></tr><tr><td>class_acc_Arachnida</td><td>0.825</td></tr><tr><td>class_acc_Aves</td><td>0.93</td></tr><tr><td>class_acc_Fungi</td><td>0.87</td></tr><tr><td>class_acc_Insecta</td><td>0.82</td></tr><tr><td>class_acc_Mammalia</td><td>0.9</td></tr><tr><td>class_acc_Mollusca</td><td>0.81</td></tr><tr><td>class_acc_Plantae</td><td>0.79</td></tr><tr><td>class_acc_Reptilia</td><td>0.845</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>test_accuracy</td><td>0.844</td></tr><tr><td>train_accuracy</td><td>0.90236</td></tr><tr><td>train_loss</td><td>0.32915</td></tr><tr><td>training_time</td><td>1220.13136</td></tr><tr><td>val_accuracy</td><td>0.8395</td></tr><tr><td>val_loss</td><td>0.52443</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">resnet50-c10-b32-lr1.0e-03-0419-ugx</strong> at: <a href='https://wandb.ai/da24m012-iit-madras/A2/runs/tkutrcpc' target=\"_blank\">https://wandb.ai/da24m012-iit-madras/A2/runs/tkutrcpc</a><br> View project at: <a href='https://wandb.ai/da24m012-iit-madras/A2' target=\"_blank\">https://wandb.ai/da24m012-iit-madras/A2</a><br>Synced 5 W&B file(s), 3 media file(s), 18 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250419_063712-tkutrcpc/logs</code>"},"metadata":{}},{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}